{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BasicTensorConcept\n",
    "\n",
    "Tensor：它有點像是Array 但是在pytorch中他常常被 model 用來encode 或是 decode一些東西\n",
    "\n",
    "Tensor與numpy有點像 唯一不同的是tensor是可以在GPU上面執行來加速效能，在底層邏輯中tensors跟numpy是共享同一個mempory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 從原始資料轉換tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data  = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x_data)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 從numpy中轉換到Tensor\n",
    "\n",
    "numpy可以轉透過from_numpy(nparray)做轉換\n",
    "\n",
    "同時原始的np_array做運算之後，tensor也跟著做變更\n",
    "\n",
    "所以可以看到其實tensor跟numpy是共享同一個記憶體位址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy np_array value: \n",
      " [[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Tensor x_np value: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32) \n",
      "\n",
      "Numpy np_array after * 2 operation: \n",
      " [[2 4]\n",
      " [6 8]] \n",
      "\n",
      "Tensor x_np value after modifying numpy array: \n",
      " tensor([[2, 4],\n",
      "        [6, 8]], dtype=torch.int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"Numpy np_array value: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value: \\n {x_np} \\n\")\n",
    "\n",
    "np.multiply(np_array, 2, out=np_array)\n",
    "\n",
    "print(f\"Numpy np_array after * 2 operation: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要複製\"屬性\"一模一樣的tensor 可以用ones_like\n",
    "他可以保留與原始資料一樣的shape跟資料型態而不干擾到原始型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.0919, 0.4736],\n",
      "        [0.3236, 0.4089]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f'Ones Tensor: \\n {x_ones} \\n')\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立新的tensor 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8136, 0.9171, 0.9752],\n",
      "        [0.1741, 0.8314, 0.8123]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, )\n",
    "# 使用隨機元素建立\n",
    "temp = torch.rand(size = shape)\n",
    "print(temp)\n",
    "print(temp.shape)\n",
    "# 建立ones元素陣列\n",
    "temp = torch.ones(size = shape)\n",
    "print(temp)\n",
    "print(temp.shape)\n",
    "# 建立zeros元素陣列\n",
    "temp = torch.zeros(size = shape)\n",
    "print(temp)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8286,  0.6395, -0.2504, -1.1938],\n",
      "        [-0.6927, -0.7083,  1.0401,  1.1860],\n",
      "        [ 0.6795,  0.3633, -0.9841, -0.1884],\n",
      "        [ 0.5161,  1.4558, -0.3185,  1.0774]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.randn(4 , 4)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor屬性\n",
    "tensor 共會有幾個重要的屬性\n",
    "\n",
    "1. shape 描述該tensor共會有幾個軸 比如影像為 (batch, C, H, W)四個軸\n",
    "2. dtype 該tensor內部的資料型態 每個元素的資料型態 比如float32等...\n",
    "3. device 該tensor目前隸屬那些裝置來進行運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape = torch.Size([3, 4])\n",
      "Datatype = torch.float32\n",
      "Device = cpu\n",
      "Change tensor to GPU\n",
      "Device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(size=(3, 4))\n",
    "\n",
    "print(f'tensor shape = {tensor.shape}')\n",
    "print(f'Datatype = {tensor.dtype}')\n",
    "print(f'Device = {tensor.device}')\n",
    "\n",
    "# 可以透過tensor.to的方式轉換到GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Change tensor to GPU')\n",
    "    tensor = tensor.to('cuda:0')\n",
    "    print(f'Device = {tensor.device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data : tensor([[0.1906, 0.5531, 0.4673, 0.9709],\n",
      "        [0.3126, 0.9515, 0.7070, 0.5775],\n",
      "        [0.2041, 0.9852, 0.6762, 0.1640],\n",
      "        [0.1743, 0.5197, 0.2265, 0.5147]])\n",
      "First row : tensor([0.1906, 0.5531, 0.4673, 0.9709])\n",
      "First col : tensor([0.1906, 0.3126, 0.2041, 0.1743])\n",
      "Last col : tensor([0.9709, 0.5775, 0.1640, 0.5147])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((4, 4))\n",
    "print(f'Raw Data : {tensor}')\n",
    "print(f'First row : {tensor[0]}')\n",
    "print(f'First col : {tensor[:, 0]}')\n",
    "print(f'Last col : {tensor[..., -1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed Data : tensor([[0.1906, 0.0000, 0.4673, 0.9709],\n",
      "        [0.3126, 0.0000, 0.7070, 0.5775],\n",
      "        [0.2041, 0.0000, 0.6762, 0.1640],\n",
      "        [0.1743, 0.0000, 0.2265, 0.5147]])\n"
     ]
    }
   ],
   "source": [
    "# Change Data\n",
    "tensor[:, 1] = 0\n",
    "print(f'Changed Data : {tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1906)\n",
      "tensor(0.)\n",
      "tensor(0.4673)\n",
      "tensor(0.9709)\n",
      "tensor(0.3126)\n",
      "tensor(0.)\n",
      "tensor(0.7070)\n",
      "tensor(0.5775)\n",
      "tensor(0.2041)\n",
      "tensor(0.)\n",
      "tensor(0.6762)\n",
      "tensor(0.1640)\n",
      "tensor(0.1743)\n",
      "tensor(0.)\n",
      "tensor(0.2265)\n",
      "tensor(0.5147)\n"
     ]
    }
   ],
   "source": [
    "# 歷遍所有元素\n",
    "for i in tensor:\n",
    "    for j in i:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1906, 0.0000, 0.4673, 0.9709, 0.1906, 0.0000, 0.4673, 0.9709, 0.1906,\n",
      "         0.0000, 0.4673, 0.9709],\n",
      "        [0.3126, 0.0000, 0.7070, 0.5775, 0.3126, 0.0000, 0.7070, 0.5775, 0.3126,\n",
      "         0.0000, 0.7070, 0.5775],\n",
      "        [0.2041, 0.0000, 0.6762, 0.1640, 0.2041, 0.0000, 0.6762, 0.1640, 0.2041,\n",
      "         0.0000, 0.6762, 0.1640],\n",
      "        [0.1743, 0.0000, 0.2265, 0.5147, 0.1743, 0.0000, 0.2265, 0.5147, 0.1743,\n",
      "         0.0000, 0.2265, 0.5147]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat(tensors=[tensor, tensor, tensor], dim = 1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩陣運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 = tensor([[0.1644, 0.1582, 0.6344, 0.7900],\n",
      "        [0.6341, 0.2995, 0.1887, 0.0134],\n",
      "        [0.5629, 0.4653, 0.7051, 0.8102],\n",
      "        [0.3696, 0.2450, 0.2284, 0.6678]])\n",
      "m2 = tensor([[0.8074, 0.0597, 0.3045, 0.9804],\n",
      "        [0.3369, 0.0028, 0.6626, 0.7497],\n",
      "        [0.9107, 0.9256, 0.9950, 0.0820],\n",
      "        [0.7962, 0.7808, 0.7743, 0.0775]])\n",
      "m1 shape = torch.Size([4, 4])\n",
      "m2 shpae = torch.Size([4, 4])\n",
      "y1 = tensor([[1.1099, 1.0685, 0.9921, 0.8068],\n",
      "        [0.6004, 0.3495, 1.0436, 0.8858],\n",
      "        [1.4913, 1.2656, 1.7113, 1.4202],\n",
      "        [1.0373, 0.7772, 0.8454, 0.7142]])\n",
      "y1 shape = torch.Size([4, 4])\n",
      "---------------------------------------------\n",
      "m1 = tensor([[0.3401, 0.3171, 0.0898, 0.1658],\n",
      "        [0.7296, 0.6628, 0.3616, 0.0979],\n",
      "        [0.7998, 0.1008, 0.5210, 0.1333],\n",
      "        [0.1231, 0.3209, 0.6630, 0.7547]])\n",
      "m2 = tensor([[0.3571, 0.5069, 0.0448, 0.6877, 0.3637],\n",
      "        [0.9683, 0.5788, 0.9322, 0.4542, 0.8500],\n",
      "        [0.2899, 0.9470, 0.7217, 0.7674, 0.9836],\n",
      "        [0.1565, 0.2711, 0.1330, 0.2575, 0.9474]])\n",
      "m1 shape = torch.Size([4, 4])\n",
      "m2 shpae = torch.Size([4, 5])\n",
      "y1 = tensor([[0.4805, 0.4860, 0.3977, 0.4895, 0.6387],\n",
      "        [1.0225, 1.1225, 0.9246, 1.1055, 1.2771],\n",
      "        [0.5551, 0.9934, 0.5236, 1.0300, 1.0153],\n",
      "        [0.6649, 1.0806, 0.8835, 0.9335, 1.6846]])\n",
      "y1 shape = torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 矩陣相乘\n",
    "m1 = torch.rand((4,4))\n",
    "m2 = torch.rand((4,4))\n",
    "print(f'm1 = {m1}')\n",
    "print(f'm2 = {m2}')\n",
    "print(f'm1 shape = {m1.shape}')\n",
    "print(f'm2 shpae = {m2.shape}')\n",
    "y1 = m1 @ m2.T\n",
    "# 也可以使用y1 = m1.matmul(m2.T)\n",
    "print(f'y1 = {y1}')\n",
    "print(f'y1 shape = {y1.shape}')\n",
    "print(\"---------------------------------------------\")\n",
    "m1 = torch.rand((4,4))\n",
    "m2 = torch.rand((4,5))\n",
    "print(f'm1 = {m1}')\n",
    "print(f'm2 = {m2}')\n",
    "print(f'm1 shape = {m1.shape}')\n",
    "print(f'm2 shpae = {m2.shape}')\n",
    "y1 = m1 @ m2\n",
    "print(f'y1 = {y1}')\n",
    "print(f'y1 shape = {y1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 = tensor([[0.4472, 0.6453, 0.5542, 0.5489],\n",
      "        [0.7472, 0.3277, 0.9373, 0.8724],\n",
      "        [0.0210, 0.1407, 0.5056, 0.3060],\n",
      "        [0.9877, 0.2447, 0.4710, 0.0894]])\n",
      "m2 = tensor([[0.0792, 0.9685, 0.1150, 0.7373],\n",
      "        [0.4023, 0.4345, 0.5059, 0.3268],\n",
      "        [0.0694, 0.8801, 0.3044, 0.6205],\n",
      "        [0.6359, 0.3298, 0.1460, 0.9968]])\n",
      "y1 = tensor([[0.0354, 0.6250, 0.0637, 0.4047],\n",
      "        [0.3006, 0.1424, 0.4742, 0.2851],\n",
      "        [0.0015, 0.1238, 0.1539, 0.1899],\n",
      "        [0.6281, 0.0807, 0.0688, 0.0891]])\n"
     ]
    }
   ],
   "source": [
    "# 矩陣元素積 element-wise product\n",
    "m1 = torch.rand((4,4))\n",
    "m2 = torch.rand((4,4))\n",
    "print(f'm1 = {m1}')\n",
    "print(f'm2 = {m2}')\n",
    "y1 = m1 * m2\n",
    "# 也可以使用 y1 = m1.mul(m2)\n",
    "print(f'y1 = {y1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor single-element item\n",
    "\n",
    "tensor可以透過item這個method來取出python中的number資料結構(不會被其他運算受影響的數值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor = tensor([[0.4991, 0.6966, 0.6872, 0.5338],\n",
      "        [0.6336, 0.0129, 0.2824, 0.0290],\n",
      "        [0.7241, 0.5805, 0.6654, 0.0473],\n",
      "        [0.8945, 0.0429, 0.7326, 0.3914]])\n",
      "agg = 7.453608512878418\n",
      "agg_item = 7.453608512878418\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((4, 4))\n",
    "print(f'tensor = {tensor}')\n",
    "agg = tensor.sum()\n",
    "print(f'agg = {agg}')\n",
    "agg_item = agg.item()\n",
    "print(f'agg_item = {agg_item}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor 與 numpy的關係\n",
    "\n",
    "tensor 跟 numpy雖然結構不同，但彼此之間是共享同一個記憶體位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f't: {t}')\n",
    "n = t.numpy()\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out = n)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# argmax函式\n",
    "代表從這個tensor中找出最大的值以及他的index\n",
    "\n",
    "裡面有個超參數 keepdim是否保持原始shape 找出每個裡面最大的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(type(torch.argmax(temp) == 11))\n",
    "print((torch.argmax(temp) == 11).type(torch.float).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 1]])\n",
      "tensor([[0, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(temp, dim=0, keepdim=True))\n",
    "print(temp.argmax(dim = 0, keepdim= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "118d2d70b9837ec74e99cd8e271bd7c1e24309015268c38b027840ab45e80ec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
